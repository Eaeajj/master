# Отчёт

пришлось очень много править код: делать функции чистыми и убирать переопределения переменных, чтобы можно было спокойно работать отдельно с каждой ячейкой.

### Выводы
Научился решать простые задачи линейной регрессии. Формулы составлял сразу для n-мерного набора признаков. Рассмотрел 2 метода оптимизации линейной модели такие как: градиентный спуск и систему нормальных уравнений. Также рассмотрел зависимость между скоростью обучения $\alpha$ и функцией стоимости.